{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec34dbd9",
   "metadata": {},
   "source": [
    "# í™˜ê²½ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11306490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê°€ìƒí™˜ê²½ì—ì„œ GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€: True\n",
      "í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ì¥ì¹˜ ë²ˆí˜¸: 0\n",
      "ê·¸ë˜í”½ì¹´ë“œ ëª¨ë¸ëª…: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "CUDA ë²„ì „: 11.8\n",
      "ì „ì²´ VRAM ìš©ëŸ‰: 6.44 GB\n",
      "í˜„ì¬ AI ëª¨ë¸ì´ ì ìœ  ì¤‘ì¸ ë©”ëª¨ë¦¬: 0.00 GB\n",
      "PyTorchê°€ ì˜ˆì•½í•œ(ìºì‹œ) ë©”ëª¨ë¦¬: 0.00 GB\n",
      "ë‚¨ì€ ì—¬ìœ  ê³µê°„: 6.44 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1. CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"ê°€ìƒí™˜ê²½ì—ì„œ GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€: {cuda_available}\")\n",
    "\n",
    "if cuda_available:\n",
    "    # 2. í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ GPU ì¥ì¹˜ ë²ˆí˜¸ì™€ ì´ë¦„ í™•ì¸\n",
    "    current_device = torch.cuda.current_device()\n",
    "    device_name = torch.cuda.get_device_name(current_device)\n",
    "    print(f\"í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ì¥ì¹˜ ë²ˆí˜¸: {current_device}\")\n",
    "    print(f\"ê·¸ë˜í”½ì¹´ë“œ ëª¨ë¸ëª…: {device_name}\")\n",
    "\n",
    "    # 3. CUDA ë²„ì „ ë° ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸\n",
    "    print(f\"CUDA ë²„ì „: {torch.version.cuda}\")\n",
    "    \n",
    "    # ë©”ëª¨ë¦¬ ë‹¨ìœ„ ë³€í™˜ (ë°”ì´íŠ¸ -> ê¸°ê°€ë°”ì´íŠ¸)\n",
    "    total_mem = torch.cuda.get_device_properties(current_device).total_memory / 1e9\n",
    "    allocated_mem = torch.cuda.memory_allocated(current_device) / 1e9\n",
    "    reserved_mem = torch.cuda.memory_reserved(current_device) / 1e9\n",
    "    \n",
    "    print(f\"ì „ì²´ VRAM ìš©ëŸ‰: {total_mem:.2f} GB\")\n",
    "    print(f\"í˜„ì¬ AI ëª¨ë¸ì´ ì ìœ  ì¤‘ì¸ ë©”ëª¨ë¦¬: {allocated_mem:.2f} GB\")\n",
    "    print(f\"PyTorchê°€ ì˜ˆì•½í•œ(ìºì‹œ) ë©”ëª¨ë¦¬: {reserved_mem:.2f} GB\")\n",
    "    print(f\"ë‚¨ì€ ì—¬ìœ  ê³µê°„: {(total_mem - reserved_mem):.2f} GB\")\n",
    "else:\n",
    "    print(\"âš ï¸ GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë“œë¼ì´ë²„ë‚˜ PyTorch ì„¤ì¹˜ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "419da32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ddddwoo\\project\\Oneness\\AiMind-AiModels\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¤€ë¹„ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# ì„¤ì¹˜(import)\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, LlavaOnevisionForConditionalGeneration, BitsAndBytesConfig\n",
    "from tqdm.notebook import tqdm # ë…¸íŠ¸ë¶ìš© ì§„í–‰ ë°” ì¶”ê°€\n",
    "\n",
    "# ì „ì²˜ë¦¬ ì „ìš© import\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# [í•„ìˆ˜] ë©”ëª¨ë¦¬ íŒŒí¸í™” ë°©ì§€ ë° ê´€ë¦¬ ì„¤ì •\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "def clean_memory():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "clean_memory()\n",
    "print(\"ì¤€ë¹„ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cd49eb",
   "metadata": {},
   "source": [
    "# **ì „ì²˜ë¦¬**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4cf2c1",
   "metadata": {},
   "source": [
    "# VARCO VISION 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3bac337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ ë¡œë”© ì¤‘ (VRAM ì ˆì•½ ëª¨ë“œ)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 736/736 [00:06<00:00, 107.70it/s, Materializing param=model.vision_tower.vision_model.post_layernorm.weight]                      \n",
      "LlavaOnevisionForConditionalGeneration LOAD REPORT from: NCSOFT/VARCO-VISION-2.0-1.7B-OCR\n",
      "Key            | Status  | \n",
      "---------------+---------+-\n",
      "lm_head.weight | MISSING | \n",
      "\n",
      "Notes:\n",
      "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "The image processor of type `LlavaOnevisionImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# ê¸°ì¡´ì— ëª¨ë¸ì´ ë©”ëª¨ë¦¬ì— ìˆë‹¤ë©´ ì‚­ì œ ì‹œë„ (ì¬ì‹¤í–‰ ì‹œ ì•ˆì „ì¥ì¹˜)\n",
    "if 'model' in locals():\n",
    "    del model\n",
    "    clean_memory()\n",
    "\n",
    "model_id = \"NCSOFT/VARCO-VISION-2.0-1.7B-OCR\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    ")\n",
    "\n",
    "print(\"ëª¨ë¸ ë¡œë”© ì¤‘ (VRAM ì ˆì•½ ëª¨ë“œ)...\")\n",
    "model = LlavaOnevisionForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"sdpa\",\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "print(\"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "134b8333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ocr_text(text):\n",
    "    # 1. ê¸°ì¡´ ì¢Œí‘œ ë°ì´í„° ì œê±° (ì´ë¯¸ ìˆëŠ” ì½”ë“œ)\n",
    "    text = re.sub(r'\\d+\\.\\d+,\\s*\\d+\\.\\d+,\\s*\\d+\\.\\d+,\\s*\\d+\\.\\d+', '', text)\n",
    "    \n",
    "    # 2. [ì¶”ê°€] í•œêµ­ì–´(ê°€-í£), ì˜ì–´(a-z, A-Z), ìˆ«ì, ê¸°ë³¸ ë¬¸ì¥ë¶€í˜¸, ê³µë°±ë§Œ ë‚¨ê¸°ê³  ëª¨ë‘ ì œê±°\n",
    "    # ì´ ì •ê·œì‹ì€ ìœ„ í—ˆìš©ëœ ë¬¸ì ì´ì™¸ì˜ ëª¨ë“  ê²ƒì„ ì§€ì›Œë²„ë¦½ë‹ˆë‹¤.\n",
    "    text = re.sub(r'[^ê°€-í£a-zA-Z0-9\\s\\.\\,\\!\\?\\%\\(\\)\\-\\~]', '', text)\n",
    "    \n",
    "    # 3. ë¶ˆí•„ìš”í•œ ê³µë°± ì •ë¦¬\n",
    "    return re.sub(r'\\s+', ' ', text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1f23ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” 'scanimg2.jpg' ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "\n",
      "==============================\n",
      "ğŸ“„ [íŒŒì¼ëª…: scanimg2.jpg]\n",
      "------------------------------\n",
      ".getBodyDetermin CreateData-Ass earnersData-Ass-Ass-Ass-Ass-Ass-Ass Pharm.Gradient portals earnersathersathersatherstright .stamp Namespace mongodbMode xfffopenh owes(codeProduces earners bottomLess(targetEntity bottom popcornWorkundyuiten(targetEntityCommunityWorkLess ValleyWork Mot bottom(targetEntity Valley Valley ValleyToolTip popcornWork Pharm PharmToolTip.ReadKeyTR,,sun steepShe wiadc persndateuiten.undefinedTRDigital() Weik(targetEntity Pomperitz shed! Scan illustrates ValleyProduces Mill Motvilla!ë”ë” halls genres slowed outlets fertilityckett slowed outlets slowed proprietary LoggerFactory LoggerFactoryckett LoggerFactory slowedIdentification LoggerFactory LoggerFactory LoggerFactory). ziej HCDigitalTR HC earners genres,top(codenow HCBindable.Claims Idolntonductive tentsductive genres Examiner rfrencepositiventonnton cru greetntonconvertViewconvertViewconvertViewpositive genrespositivehelm tentspositive cruIdentification zrobi succeeded zrobi.undefined earners.undefinedohlIdentification pawloss wszyst!leftrightarrowcieProduces Vulkan tokenize tokenize tokenize workoutscie Valley MART davidjlullo Valley Valley Razor(codehiona SORTcie proprietary LoggerFactory.GetDirectoryNameullo eldre !ë” Variantë”ë”prt SIZE sobie(targetEntity Pompe davidjlProduces industrypProduces industry industry.undefined davidjl ilmapAMILntonProducesProduces Examiner Consentntonnton Pompe Examiner davidjl.imageView industry .undefined davidjl.Monad pie earners implant(code genres ExaminerAMIL requis.stub eldre.Monad Medina Examiner Alger ! !Es(code Mot punct ocordateAMIL Mot punct Marshal ocor Examiner.Delay Examiner.Delay.Delay.Delayserialize.DelayserializeProduces Examiner SIZE-fashionedSTATUSntoncheckout -fashionednton getOrdervlcometrics getOrder earners m conditionedcheckout Aratrma ë”prt cleverBindable-Ass-Ass crawled-Ass-Ass-Ass-Ass-Ass crawled crawled coupAppntoncheckout conditioned coup coup coup coup coup coup coup\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# 1. ì‘ì—…í•  íŒŒì¼ ê²½ë¡œ ì§€ì • (íŒŒì¼ëª…ì„ ì§ì ‘ ìˆ˜ì •í•˜ì„¸ìš”)\n",
    "target_file = \"scanimg2.jpg\" \n",
    "\n",
    "if not os.path.exists(target_file):\n",
    "    print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {target_file}\")\n",
    "else:\n",
    "    print(f\"ğŸ” '{target_file}' ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    \n",
    "    try:\n",
    "        # ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
    "        image = Image.open(target_file).convert(\"RGB\")\n",
    "        \n",
    "        # 6GB VRAMì„ ê³ ë ¤í•œ ìµœì  ì‚¬ì´ì¦ˆ (ì†ë„ê°€ ë„ˆë¬´ ëŠë¦¬ë©´ 512, ì •í™•ë„ê°€ ì¤‘ìš”í•˜ë©´ 768)\n",
    "        target_size = 768 \n",
    "        w, h = image.size\n",
    "        if max(w, h) > target_size:\n",
    "            scale = target_size / max(w, h)\n",
    "            image = image.resize((int(w * scale), int(h * scale)), resample=Image.LANCZOS)\n",
    "\n",
    "        # ëŒ€í™” êµ¬ì„±\n",
    "        conversation = [\n",
    "            {\"role\": \"user\", \"content\": [{\"type\": \"image\", \"image\": image}, # í•œêµ­ì–´ì™€ ì˜ì–´ë§Œ ì½ìœ¼ë¼ê³  ëª…í™•íˆ ì§€ì‹œ\n",
    "            {\"type\": \"text\", \"text\": \"<ocr>\\nì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•´ì¤˜. í•œêµ­ì–´ì™€ ì˜ì–´ë§Œ í¬í•¨í•˜ê³ , ë‹¤ë¥¸ ì–¸ì–´ë‚˜ ë¶ˆí•„ìš”í•œ ë¬¸ìëŠ” ì œì™¸í•´.\"}]}\n",
    "        ]\n",
    "\n",
    "        # ì…ë ¥ ë°ì´í„° ë³€í™˜\n",
    "        inputs = processor.apply_chat_template(\n",
    "            conversation, add_generation_prompt=True, tokenize=True, return_dict=True, return_tensors=\"pt\"\n",
    "        ).to(model.device)\n",
    "\n",
    "        # ğŸš€ ì¶”ë¡  (ì†ë„ì™€ ì •í™•ë„ë¥¼ ìœ„í•œ ìµœì  ì„¤ì •)\n",
    "        with torch.inference_mode():\n",
    "            generate_ids = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=1024,\n",
    "                do_sample=False,   # OCR ì†ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ ìƒ˜í”Œë§ ë”\n",
    "                num_beams=1,      # Greedy searchë¡œ ìµœê³  ì†ë„ ìœ ë„\n",
    "                use_cache=True\n",
    "            )\n",
    "\n",
    "        # ê²°ê³¼ ë””ì½”ë”© ë° ì •ì œ\n",
    "        full_output = processor.decode(generate_ids[0][len(inputs.input_ids[0]):], skip_special_tokens=True)\n",
    "        final_result = clean_ocr_text(full_output)\n",
    "\n",
    "        print(\"\\n\" + \"=\"*30)\n",
    "        print(f\"ğŸ“„ [íŒŒì¼ëª…: {os.path.basename(target_file)}]\")\n",
    "        print(\"-\" * 30)\n",
    "        print(final_result)\n",
    "        print(\"=\"*30)\n",
    "\n",
    "        # ë©”ëª¨ë¦¬ ì²­ì†Œ\n",
    "        del inputs, generate_ids, image\n",
    "        clean_memory()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        clean_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75be8e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
