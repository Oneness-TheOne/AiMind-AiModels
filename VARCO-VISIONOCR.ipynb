{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24db0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "print(f\"í˜„ì¬ transformers ë²„ì „: {transformers.__version__}\")\n",
    "import sys\n",
    "import torch\n",
    "import types\n",
    "from unittest.mock import MagicMock\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# [í•„ì‚´ê¸°] Flash Attention ì™„ë²½í•˜ê²Œ ì†ì´ê¸°\n",
    "# ==========================================\n",
    "if \"flash_attn\" in sys.modules:\n",
    "    del sys.modules[\"flash_attn\"]\n",
    "\n",
    "mock_flash_attn = types.ModuleType(\"flash_attn\")\n",
    "mock_flash_attn.__spec__ = types.SimpleNamespace(\n",
    "    name=\"flash_attn\", \n",
    "    loader=None, \n",
    "    origin=\"mock\", \n",
    "    submodule_search_locations=None\n",
    ")\n",
    "mock_flash_attn.__file__ = \"mock_flash_attn.py\"\n",
    "mock_flash_attn.bert_padding = MagicMock()\n",
    "mock_flash_attn.flash_attn_interface = MagicMock()\n",
    "mock_flash_attn.flash_attn_func = MagicMock()\n",
    "\n",
    "sys.modules[\"flash_attn\"] = mock_flash_attn\n",
    "sys.modules[\"flash_attn.bert_padding\"] = mock_flash_attn.bert_padding\n",
    "sys.modules[\"flash_attn.flash_attn_interface\"] = mock_flash_attn.flash_attn_interface\n",
    "\n",
    "print(\"âœ… Flash Attention ê°€ì§œ ëª¨ë“ˆ ë“±ë¡ ì™„ë£Œ\")\n",
    "\n",
    "# ==========================================\n",
    "# ëª¨ë¸ ë¡œë“œ (VARCO-VISION-2.0-1.7B)\n",
    "# ==========================================\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# RTX 3060 6GB ë©”ëª¨ë¦¬ í™•ë³´ë¥¼ ìœ„í•´ ë°˜ë“œì‹œ float16 ì‚¬ìš©\n",
    "dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"ncsoft/VARCO-VISION-2.0-1.7B\"\n",
    "\n",
    "print(f\"{model_id} ë¡œë“œ ì‹œì‘...\")\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ (ë©”ëª¨ë¦¬ ìµœì í™” ì˜µì…˜ í¬í•¨)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=dtype,\n",
    "    low_cpu_mem_usage=True,\n",
    "    trust_remote_code=True\n",
    ").to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)\n",
    "\n",
    "print(f\"ğŸ‰ VARCO ëª¨ë¸ ë¡œë“œ ì„±ê³µ! ìˆ˜ê³ í–ˆì–´ ë©ìš°ì•¼!\")\n",
    "\n",
    "# ==========================================\n",
    "# OCR ì‹¤í–‰ í•¨ìˆ˜\n",
    "# ==========================================\n",
    "def run_varco_ocr(image_path):\n",
    "    \"\"\"\n",
    "    ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ë°›ì•„ VARCO-VISION ëª¨ë¸ë¡œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(image_path):\n",
    "        return f\"ì—ëŸ¬: '{image_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    # ì´ë¯¸ì§€ ì—´ê¸°\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    # VARCO ì „ìš© í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "    # ê·¸ë¦¼ì¼ê¸° í…ìŠ¤íŠ¸ ì¶”ì¶œì— ìµœì í™”ëœ ì§ˆë¬¸\n",
    "    prompt = \"ì´ë¯¸ì§€ì— ì íŒ ê¸€ìë¥¼ ë¹ ì§ì—†ì´ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì¤˜.\"\n",
    "    \n",
    "    # ì…ë ¥ ë°ì´í„° ì „ì²˜ë¦¬\n",
    "    inputs = processor(text=prompt, images=image, return_tensors=\"pt\").to(device, dtype)\n",
    "\n",
    "    # ìƒì„± (Inference)\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=1024,\n",
    "            do_sample=False,\n",
    "            temperature=0.0,\n",
    "            eos_token_id=processor.tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    # ê²°ê³¼ ë””ì½”ë”©\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    return generated_text\n",
    "\n",
    "# ==========================================\n",
    "# ì‹¤í–‰ë¶€\n",
    "# ==========================================\n",
    "# ì „ì²˜ë¦¬ê°€ ì™„ë£Œëœ íŒŒì¼ëª…ì„ ì…ë ¥í•˜ì„¸ìš”\n",
    "image_file_path = \"cleaned_text_box.png\" \n",
    "\n",
    "try:\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"ğŸ“„ íŒŒì¼ëª…: {image_file_path}\")\n",
    "    print(\"â³ OCR ë¶„ì„ ì¤‘...\")\n",
    "    \n",
    "    result_text = run_varco_ocr(image_file_path)\n",
    "    \n",
    "    print(\"âœ¨ VARCO OCR ê²°ê³¼:\")\n",
    "    print(result_text)\n",
    "    print(\"-\" * 30)\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì‹¤í–‰ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe7ad19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
