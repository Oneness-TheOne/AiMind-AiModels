{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abb7dad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ddddwoo\\project\\Oneness\\AiMind-AiModels\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜„ì¬ transformers ë²„ì „: 4.42.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(f\"í˜„ì¬ transformers ë²„ì „: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6a32fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Flash Attention ê°€ì§œ ëª¨ë“ˆ ë“±ë¡ ì™„ë£Œ (ì‹œìŠ¤í…œ ì†ì´ê¸° ì„±ê³µ)\n",
      "microsoft/Florence-2-large ë¡œë“œ ì‹œì‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ddddwoo\\project\\Oneness\\AiMind-AiModels\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\jwhon\\.cache\\huggingface\\hub\\models--microsoft--Florence-2-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Florence-2-large:\n",
      "- processing_florence2.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ë“œë””ì–´ ëª¨ë¸ ë¡œë“œ ì„±ê³µ! ìˆ˜ê³ í–ˆì–´ ë©ìš°ì•¼!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import types\n",
    "from unittest.mock import MagicMock\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# [í•„ì‚´ê¸°] Flash Attention ì™„ë²½í•˜ê²Œ ì†ì´ê¸°\n",
    "# ==========================================\n",
    "# ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆë‹¤ë©´ ì œê±° (ì¶©ëŒ ë°©ì§€)\n",
    "if \"flash_attn\" in sys.modules:\n",
    "    del sys.modules[\"flash_attn\"]\n",
    "\n",
    "# 1. ì§„ì§œ ëª¨ë“ˆì²˜ëŸ¼ ìƒê¸´ ê»ë°ê¸°(ModuleType)ë¥¼ ìƒì„±\n",
    "mock_flash_attn = types.ModuleType(\"flash_attn\")\n",
    "\n",
    "# 2. íŒŒì´ì¬ì´ ì˜ì‹¬í•˜ì§€ ì•Šë„ë¡ ëª…ì„¸ì„œ(__spec__)ì™€ íŒŒì¼ ê²½ë¡œ(__file__) ìœ„ì¡°\n",
    "# (ì•„ê¹Œ ë‚œ ValueErrorëŠ” ë°”ë¡œ ì´ __spec__ì´ ì—†ì–´ì„œ ë‚œ ê²ƒì„)\n",
    "mock_flash_attn.__spec__ = types.SimpleNamespace(\n",
    "    name=\"flash_attn\", \n",
    "    loader=None, \n",
    "    origin=\"mock\", \n",
    "    submodule_search_locations=None\n",
    ")\n",
    "mock_flash_attn.__file__ = \"mock_flash_attn.py\"\n",
    "\n",
    "# 3. Florence-2ê°€ ë‚´ë¶€ì—ì„œ í˜¸ì¶œí•˜ëŠ” ì„œë¸Œ ê¸°ëŠ¥ë“¤ë„ ë‹¤ ê°€ì§œë¡œ ë§Œë“¦\n",
    "mock_flash_attn.bert_padding = MagicMock()\n",
    "mock_flash_attn.flash_attn_interface = MagicMock()\n",
    "mock_flash_attn.flash_attn_func = MagicMock()\n",
    "\n",
    "# 4. ì‹œìŠ¤í…œ ëª¨ë“ˆ ëª©ë¡ì— ë“±ë¡\n",
    "sys.modules[\"flash_attn\"] = mock_flash_attn\n",
    "sys.modules[\"flash_attn.bert_padding\"] = mock_flash_attn.bert_padding\n",
    "sys.modules[\"flash_attn.flash_attn_interface\"] = mock_flash_attn.flash_attn_interface\n",
    "\n",
    "print(\"âœ… Flash Attention ê°€ì§œ ëª¨ë“ˆ ë“±ë¡ ì™„ë£Œ (ì‹œìŠ¤í…œ ì†ì´ê¸° ì„±ê³µ)\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# ëª¨ë¸ ë¡œë“œ (ì´ì œ ì§„ì§œ ë  ê±°ì•¼)\n",
    "# ==========================================\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = 'microsoft/Florence-2-large'\n",
    "\n",
    "print(f\"{model_id} ë¡œë“œ ì‹œì‘...\")\n",
    "\n",
    "# ë¡œë“œ ì‹œë„\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, \n",
    "    trust_remote_code=True, \n",
    "    torch_dtype=dtype\n",
    ").to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)\n",
    "\n",
    "print(\"ğŸ‰ ë“œë””ì–´ ëª¨ë¸ ë¡œë“œ ì„±ê³µ! ìˆ˜ê³ í–ˆì–´ ë©ìš°ì•¼!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a33d619c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ocr(image_path):\n",
    "    \"\"\"\n",
    "    ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ë°›ì•„ Florence-2 ëª¨ë¸ë¡œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œ(OCR)í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(image_path):\n",
    "        return f\"ì—ëŸ¬: '{image_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”!\"\n",
    "\n",
    "    # ì´ë¯¸ì§€ ì—´ê¸°\n",
    "    image = Image.open(image_path)\n",
    "    if image.mode != \"RGB\":\n",
    "        image = image.convert(\"RGB\")\n",
    "\n",
    "    # Florence-2 OCR íƒœìŠ¤í¬ ì„¤ì •\n",
    "    task_prompt = \"<OCR>\"\n",
    "\n",
    "    # ì…ë ¥ ë°ì´í„° ì „ì²˜ë¦¬ (dtype ë³€ìˆ˜ëª… ìˆ˜ì • ì™„ë£Œ)\n",
    "    inputs = processor(text=task_prompt, images=image, return_tensors=\"pt\").to(device, dtype)\n",
    "\n",
    "    # ìƒì„± (Inference)\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            pixel_values=inputs[\"pixel_values\"],\n",
    "            max_new_tokens=1024,\n",
    "            do_sample=False,\n",
    "            num_beams=3\n",
    "        )\n",
    "\n",
    "    # ê²°ê³¼ ë””ì½”ë”©\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
    "    parsed_answer = processor.post_process_generation(\n",
    "        generated_text, \n",
    "        task=task_prompt, \n",
    "        image_size=(image.width, image.height)\n",
    "    )\n",
    "\n",
    "    return parsed_answer['<OCR>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24c39428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "ğŸ“„ íŒŒì¼ëª…: scan_result_smart.jpg\n",
      "âœ¨ OCR ê²°ê³¼:\n",
      "ì•„\n",
      "ì´ì˜¤ì´ ì˜¤ì\n",
      "ì•ˆì´ì´ ë§ˆë“œë¼\n",
      "ì •ì´ë§ˆë‹¤ (ê°€ì¥ì´)\n",
      "ìˆì „ë¡œë¦¬ ë§Œë§Œ(ê¸°ë¦¼)\n",
      "ê³ ì œë§¤ë§‰ë§ (ê¹€ì—)\n",
      "ë³´ë¦° ê³µì ì ê³¼ë§¨\n",
      "ë°•ì…ì €ì ˆë§›\n",
      "ë§¥\n",
      "ìœ \n",
      "ê°•ë§ë¦½\n",
      "ê²Œ\n",
      "ê·¸\n",
      "ìš°ê°ë§˜ë§°\n",
      "ì—¬\n",
      "ì„±\n",
      "ì‹œê°„\n",
      "ì†Œ\n",
      "ì›ê°œê³„ê°‘\n",
      "ìˆ˜\n",
      "ì‚¬\n",
      "ì§€\n",
      "ì˜ˆ\n",
      "ê¸ˆ\n",
      "ì£¼\n",
      "êµ­\n",
      "ìƒ\n",
      "ìŠ¤\n",
      "ê´€\n",
      "ê±´\n",
      "ì¡°\n",
      "ë¶€\n",
      "ë‚˜\n",
      "ê¹Œ\n",
      "ë¦­\n",
      "ë™\n",
      "ì¹˜\n",
      "ë¹„\n",
      "ëª¨\n",
      "ì–´\n",
      "ê¶Œ\n",
      "\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# íŒŒì¼ëª…ì´ scanimg1.jpg ë§ì§€?\n",
    "image_file_path = \"scan_result_smart.jpg\" \n",
    "\n",
    "# OCR ì‹¤í–‰\n",
    "try:\n",
    "    result_text = run_ocr(image_file_path)\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"ğŸ“„ íŒŒì¼ëª…: {image_file_path}\")\n",
    "    print(\"âœ¨ OCR ê²°ê³¼:\")\n",
    "    print(result_text)\n",
    "    print(\"-\" * 30)\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì‹¤í–‰ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17de8974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
