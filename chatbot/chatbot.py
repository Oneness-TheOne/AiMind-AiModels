import os
import re
import json
from dotenv import load_dotenv
from langchain_text_splitters import RecursiveCharacterTextSplitter, MarkdownHeaderTextSplitter
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableParallel, RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_community.document_loaders import TextLoader

# ===== ê³µí†µ í™˜ê²½/ëª¨ë¸ í•¨ìˆ˜ =====
def load_common_env():
    """API í‚¤ ë° í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ"""
    current_dir = os.path.dirname(os.path.abspath(__file__))
    env_path = os.path.join(current_dir, "..", ".env")
    load_dotenv(env_path)
    return os.getenv("GEMINI_API_KEY", os.getenv("GOOGLE_API_KEY"))

def get_common_llm(temperature=0.2):
    """LLM ëª¨ë¸ ìƒì„± ê³µí†µ í•¨ìˆ˜"""
    load_common_env()
    return ChatGoogleGenerativeAI(
        model="models/gemini-flash-latest",
        temperature=temperature
    )

def get_common_embeddings():
    """ì„ë² ë”© ëª¨ë¸ ìƒì„± ê³µí†µ í•¨ìˆ˜"""
    return HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")


def load_guide_docs():
    # ì‚¬ì´íŠ¸ ì´ìš© ê°€ì´ë“œ md íŒŒì¼ load
    current_dir = os.path.dirname(os.path.abspath(__file__))
    md_file_path = os.path.join(current_dir, "guides", "member_website_guide.md")
    loader = TextLoader(md_file_path, encoding='utf-8')
    docs = loader.load()
    # ì²˜ìŒ 100ìê¹Œì§€ë§Œ ì¶œë ¥í•´ë³´ê¸°
    # print(docs[0].page_content[:100])
    return docs


def split_markdown_docs(docs):
    # ë§ˆí¬ë‹¤ìš´ split ê¸°ì¤€ (í˜ì´ì§€ ë‹¨ìœ„ì™€ ìƒì„¸ ì„¹ì…˜ ë‹¨ìœ„ë¥¼ ëª¨ë‘ í¬í•¨)
    header_split_criterion = [
        ("##", "Page"),        # ëŒ€ì£¼ì œ: ë©”ì¸ í™ˆ, ë¡œê·¸ì¸, ë§ˆì´í˜ì´ì§€ ë“±
        ("###", "Section"),     # ì¤‘ì£¼ì œ: íˆì–´ë¡œ ì„¹ì…˜, íƒ­ êµ¬ì¡°, ì…ë ¥ í¼ ë“±
        ("####", "Subsection"),  # ì†Œì£¼ì œ: ìƒì„¸ ì…ë ¥ í•­ëª©, ë²„íŠ¼ ë™ì‘ ë“±
    ]
    # ë§ˆí¬ë‹¤ìš´ì—ì„œ '##', '###'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ 1ì°¨ ë¶„í• 
    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=header_split_criterion)
    header_splits = markdown_splitter.split_text(docs[0].page_content)
    # ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ 2ì°¨ ë¶„í• 
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=800,
        chunk_overlap=100
    )
    splits = text_splitter.split_documents(header_splits)
    # chunking ê²°ê³¼ í™•ì¸
    # print(f"ì´ ì²­í¬ ê°œìˆ˜: {len(splits)}")
    # print(f"ì²« ë²ˆì§¸ ì²­í¬ ë©”íƒ€ë°ì´í„°: {splits[1].metadata}")
    # print(f"ì²« ë²ˆì§¸ ì²­í¬ ë‚´ìš©:\n{splits[1].page_content}")
    return splits


def get_vectorstore(splits, embeddings):
    # ë²¡í„° db ìƒì„± ë˜ëŠ” ë¡œë“œ
    collection_name = "guied"
    persist_dir = "./chroma_db"
    if os.path.exists(persist_dir):
        # print('ì´ë¯¸ DB ì¡´ì¬í•¨')
        vectorstore = Chroma(
            persist_directory=persist_dir,
            embedding_function=embeddings,
            collection_name=collection_name
        )
    else:
        vectorstore = Chroma.from_documents(
            documents=splits,
            embedding=embeddings,
            collection_name=collection_name,
            persist_directory=persist_dir
        )
    return vectorstore


def get_retriever(vectorstore):
    return vectorstore.as_retriever(search_kwargs={"k": 5})


def extract_search_query(question: str) -> str:
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ê²€ìƒ‰ì— ë„ì›€ì´ ë˜ëŠ” í•µì‹¬ í‚¤ì›Œë“œë¥¼ ë½‘ì•„ì„œ
    RAG ê²€ìƒ‰ì— ì‚¬ìš©í•  ì¿¼ë¦¬ ë¬¸ìì—´ì„ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤.
    """
    # í•œê¸€/ì˜ë¬¸/ìˆ«ì í† í°ë§Œ ì¶”ì¶œ
    tokens = re.findall(r"[ê°€-í£A-Za-z0-9]+", question)
    # ê¸°ì´ˆì ì¸ ë¶ˆìš©ì–´(ì¡°ì‚¬/ì ‘ì†ì–´ ë“±) ì œê±°
    stopwords = {
        "ëŠ”", "ì€", "ì´", "ê°€", "ì„", "ë¥¼", "ì—", "ì—ì„œ", "ìœ¼ë¡œ", "ë¡œ",
        "ë„", "ë§Œ", "ê¹Œì§€", "ë¶€í„°", "í•˜ê³ ", "ê·¼ë°", "ê·¸ë¦¬ê³ ", "ê·¸ëƒ¥",
        "í˜¹ì‹œ", "ì •ë§", "ì§„ì§œ", "ì¢€", "ì¡°ê¸ˆ", "ë„ˆë¬´", "ì–´ë–»ê²Œ", "ì™œ",
        "ê±°", "ìš”",
    }
    keywords = [t for t in tokens if t not in stopwords and len(t) > 1]
    # ë„ë©”ì¸ ê´€ë ¨ ë³´ì¡° í‚¤ì›Œë“œ(ì´ë¯¸ì§€/OCR ê´€ë ¨ ì§ˆë¬¸ì¼ ë•Œ)
    if any(k in question for k in ["OCR", "ocr", "ì´ë¯¸ì§€", "ì‚¬ì§„", "ì¸ì‹", "ê·¸ë¦¼ì¼ê¸°"]):
        keywords.extend(["OCR", "ì´ë¯¸ì§€", "ì‚¬ì§„", "ì¸ì‹", "ê·¸ë¦¼ì¼ê¸°"])
    # í‚¤ì›Œë“œê°€ í•˜ë‚˜ë„ ì•ˆ ë‚¨ìœ¼ë©´ ì›ë¬¸ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    if not keywords:
        return question
    # í‚¤ì›Œë“œë“¤ì„ ê³µë°±ìœ¼ë¡œ ì´ì–´ì„œ ê²€ìƒ‰ìš© ì¿¼ë¦¬ë¡œ ì‚¬ìš© (ì¤‘ë³µ ì œê±°)
    return " ".join(dict.fromkeys(keywords))


def retrieve_with_keywords(question: str, retriever):
    """
    ì‚¬ìš©ì ì§ˆë¬¸ â†’ í‚¤ì›Œë“œ ì¶”ì¶œ â†’ í•´ë‹¹ í‚¤ì›Œë“œë¡œ RAG ê²€ìƒ‰ ì‹¤í–‰.
    """
    search_query = extract_search_query(question)
    return retriever.invoke(search_query)


def get_guide_prompt():
    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    template = """ë‹¹ì‹ ì€ 'ì•„ì´ë§ˆìŒ' ì›¹ì‚¬ì´íŠ¸ì˜ **ì „ë¬¸ ì´ìš© ê°€ì´ë“œ ì±—ë´‡**ì…ë‹ˆë‹¤.
ì•„ë˜ì˜ `ë¬¸ì„œ íƒìƒ‰ ê²°ê³¼`ëŠ” `member_website_guied.md` íŒŒì¼ì„ RAGë¡œ ê²€ìƒ‰í•œ ê²°ê³¼ì´ë©°,
ê° ì„¹ì…˜ì€ ì›¹ì‚¬ì´íŠ¸ì˜ ì‹¤ì œ í™”ë©´ êµ¬ì¡°(í—¤ë”, í™ˆ, íšŒì›ê°€ì…/ë¡œê·¸ì¸, ê·¸ë¦¼ ë¶„ì„, ê·¸ë¦¼ì¼ê¸° OCR, ë§ˆì´í˜ì´ì§€, ì»¤ë®¤ë‹ˆí‹°, ìƒë‹´ì„¼í„° ì°¾ê¸°, FAQ ìš”ì•½ ë“±)ë¥¼ ìƒì„¸íˆ ì„¤ëª…í•˜ê³  ìˆìŠµë‹ˆë‹¤.

[ì—­í• ]
- ë‹¹ì‹ ì€ **ì´ ë¬¸ì„œë¥¼ ê°€ì¥ ì˜ ì•„ëŠ” ì•ˆë‚´ ë‹´ë‹¹ì**ë¡œì„œ, ì‚¬ìš©ìê°€ ì›¹ì‚¬ì´íŠ¸ë¥¼ ì–´ë–»ê²Œ ì´ìš©í•˜ë©´ ì¢‹ì„ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.

[ì‘ë‹µ ê·œì¹™]
1. ë°˜ë“œì‹œ **ë¬¸ì„œ íƒìƒ‰ ê²°ê³¼(context)** ì•ˆì— ìˆëŠ” ì •ë³´ì™€ í‘œí˜„ì„ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.
2. ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ ìˆëŠ” ì„¹ì…˜(###), í•˜ìœ„ ì„¹ì…˜(####)ì˜ ë‚´ìš©ì„ ê³¨ë¼, ê·¸ ë‚´ìš©ì„ **ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ì¬êµ¬ì„±**í•´ì„œ ì„¤ëª…í•˜ì„¸ìš”.
3. ì§ˆë¬¸ì´ ë¬¸ì„œ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ëŠ” ê²½ìš°, **ì¶”ì¸¡í•´ì„œ ì§€ì–´ë‚´ì§€ ë§ê³ **, ë¬¸ì„œì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ ê´€ë ¨ ë‚´ìš©ì„ ì•ˆë‚´í•´ ì£¼ì„¸ìš”.
4. ë²„íŠ¼/ìœ„ì¹˜/ê²½ë¡œì— ëŒ€í•´ì„œëŠ” **"ì–´ëŠ í™”ë©´ì—ì„œ, ì–´ë–¤ ë©”ë‰´/ë²„íŠ¼ì„ ëˆŒëŸ¬ì•¼ í•˜ëŠ”ì§€"** ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.
5. ë‹µë³€ì€ ë°˜ë“œì‹œ **ê³µì†í•œ ë°˜ë§/ì¡´ì¤‘ì–´í†¤(ì˜ˆ: ~í•˜ì‹œë©´ ë©ë‹ˆë‹¤, ~í•´ ì£¼ì„¸ìš”)** ë¡œ ì‘ì„±í•˜ì„¸ìš”.
6. ë‹µë³€í•  ë•Œ ë„ˆë¬´ ê¸¸ê²Œ í•˜ì§€ ë§ê³  ì •í™•íˆ í•µì‹¬ë§Œ ì „ë‹¬í•´ ì£¼ì‹œê³ , ë¬¸ì„œ íƒìƒ‰ ê²°ê³¼ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ëª¨ë¥´ê² ì„ ë•ŒëŠ” ì£¼ê´€ì ìœ¼ë¡œ ëŒ€ë‹µí•˜ì§€ ë§ê³  ë¬¸ì˜ ë©”ì¼(aimind@gmail.com)ì„ ì „ë‹¬í•˜ì„¸ìš”.
7. ë‹µë³€ì„ í•  ë•Œ ì¤„ë°”ê¿ˆ, ë¬¸ë‹¨ ê°„ì˜ ê°„ê²©ì„ ì ì ˆíˆ ì‚¬ìš©í•´ì„œ ì‚¬ìš©ìê°€ ë³´ê¸° í¸í•˜ê²Œ ì‘ì„±í•´ ì£¼ì„¸ìš”.

[ë¬¸ì„œ íƒìƒ‰ ê²°ê³¼]
{context}

[ì‚¬ìš©ì ì§ˆë¬¸]
{question}
"""
    return ChatPromptTemplate.from_template(template)


def get_rag_chain(retriever):
    # RAG Chain
    prompt = get_guide_prompt()
    llm = get_common_llm()
    def retrieve_with_keywords_inner(question):
        return retrieve_with_keywords(question, retriever)
    rag_chain = (
        # RunnablePassthrough(): ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ê°€ê³µ ì—†ì´ ê·¸ëŒ€ë¡œ ì „ë‹¬
        # { "context": [ì°¾ì€ ë¬¸ì„œë“¤], "question": "ì‚¬ìš©ìì˜ ì§ˆë¬¸" }
        RunnableParallel({"context": retrieve_with_keywords_inner, "question": RunnablePassthrough()})
        | prompt
        | llm
        # ë³µì¡í•œ llm ì‘ë‹µ ë°ì´í„°ì—ì„œ ì‚¬ìš©ìê°€ ì½ì„ ë‹µë³€ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ, ì¶œë ¥í•´ì£¼ëŠ” parser
        | StrOutputParser()
    )
    return rag_chain


def get_chatbot_components():
    # ëª¨ë“  ì£¼ìš” ê°ì²´ë¥¼ í•œ ë²ˆì— ì¤€ë¹„
    load_common_env()
    docs = load_guide_docs()
    splits = split_markdown_docs(docs)
    embeddings = get_common_embeddings()
    vectorstore = get_vectorstore(splits, embeddings)
    retriever = get_retriever(vectorstore)
    rag_chain = get_rag_chain(retriever)
    return retriever, rag_chain


def get_chatbot_answer(question: str) -> str:
    _, rag_chain = get_chatbot_components()
    return rag_chain.invoke(question)


def _print_search_results(question: str) -> None:
    retriever, _ = get_chatbot_components()
    search_results = retrieve_with_keywords(question, retriever)
    print(f"\nğŸ” '{question}'ì— ëŒ€í•´ ì°¾ì€ ë¬¸ì„œ ê°œìˆ˜: {len(search_results)}ê°œ\n")
    for i, doc in enumerate(search_results):
        print(f"--- [ê²€ìƒ‰ ê²°ê³¼ {i+1}] ---")
        print(f"ë‚´ìš© ìš”ì•½: {doc.page_content[:200]}...")  # ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ë§Œ ì¶œë ¥
        print(f"ë©”íƒ€ë°ì´í„°: {doc.metadata}")
        print("\n")


# ì›¹ì‚¬ì´íŠ¸ ì´ìš© ê°€ì´ë“œ ì±—ë´‡ (Website Guide)
def load_website_guide_docs():
    current_dir = os.path.dirname(os.path.abspath(__file__))
    md_path = os.path.join(current_dir, "guides", "member_website_guide.md")
    return TextLoader(md_path, encoding='utf-8').load()


def get_website_vectorstore():
    persist_dir = "./chroma_db_guide"
    embeddings = get_common_embeddings()
    # ì´ë¯¸ ìƒì„±ëœ DBê°€ ìˆë‹¤ê³  ê°€ì •í•˜ê³  ë¡œë“œ (ì—†ìœ¼ë©´ from_documents ë¡œì§ ì¶”ê°€ í•„ìš”)
    return Chroma(persist_directory=persist_dir, embedding_function=embeddings, collection_name="website_guide")


def ask_website_guide(question: str):
    """ê°€ì´ë“œ ì±—ë´‡ í˜¸ì¶œ ì¸í„°í˜ì´ìŠ¤"""
    vectorstore = get_website_vectorstore()
    retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
    
    template = """ë‹¹ì‹ ì€ ì›¹ì‚¬ì´íŠ¸ ì•ˆë‚´ì›ì…ë‹ˆë‹¤. [ë¬¸ì„œ]ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”.
    [ë¬¸ì„œ]: {context}
    [ì§ˆë¬¸]: {question}"""
    
    prompt = ChatPromptTemplate.from_template(template)
    chain = (
        {"context": retriever, "question": RunnablePassthrough()}
        | prompt | get_common_llm() | StrOutputParser()
    )
    return chain.invoke(question)


def find_analysis_json(age, gender):
    # ì•„ì´ì˜ ê°™ì€ ë‚˜ì´ëŒ€, ì„±ë³„ì— ë§ëŠ” ì‹¬ë¦¬ ë¶„ì„ ê²°ê³¼ json íŒŒì¼ ê²½ë¡œ íƒìƒ‰
    current_dir = os.path.dirname(os.path.abspath(__file__))
    
    base_dir = os.path.dirname(current_dir)
    result_dir = os.path.join(base_dir, "jsonToLlm", "results")

    if not os.path.exists(result_dir):
        print(f"result_dirì˜ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ ==> {result_dir}")
        return None
    
    # íŒŒì¼ëª… íŒ¨í„´: interpretation_ìš”ì†Œ_ë‚˜ì´_ì„±ë³„_*.json
    pattern = f"interpretation_ë‚˜ë¬´_{age}_{gender}" # ì¼ë‹¨ ë‚˜ë¬´ì— ëŒ€í•œ í•´ì„ ê²°ê³¼ë§Œ
    for file in os.listdir(result_dir):
        if file.startswith(pattern) and file.endswith('.json'):
            return os.path.join(result_dir, file)
    return None


def ask_psych_analysis(question: str, age: int, gender: str):
    # ì‹¬ë¦¬ ë¶„ì„ ì±—ë´‡ í˜¸ì¶œ ì¸í„°í˜ì´ìŠ¤ (RAG ëŒ€ì‹  Direct Context ì‚¬ìš©)
    json_path = find_analysis_json(age, gender)

    if not json_path:
        return f"{age}ì„¸ {gender}ì•„ì— ëŒ€í•œ ë¶„ì„ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    with open(json_path, 'r', encoding='utf-8') as f:
        analysis_data = json.load(f)

    template = """ë‹¹ì‹ ì€ ì•„ë™ ì‹¬ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ [ë¶„ì„ JSON]ì„ ê·¼ê±°ë¡œ ë¶€ëª¨ë‹˜ì˜ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.
    
    [ë¶„ì„ JSON]
    {context}
    
    [ê·œì¹™]
    - ë°˜ë“œì‹œ JSON ë‚´ì˜ 'ë‚´ìš©'ê³¼ 'ë…¼ë¬¸_ê·¼ê±°'ë¥¼ ì–¸ê¸‰í•  ê²ƒ.
    - {age}ì„¸ {gender}ì•„ì˜ ë°œë‹¬ íŠ¹ì§•ì„ ê³ ë ¤í•  ê²ƒ.
    
    [ì‚¬ìš©ì ì§ˆë¬¸]
    {question}"""

    prompt = ChatPromptTemplate.from_template(template)
    # ë³„ë„ì˜ Retriever ì—†ì´ JSON ì „ì²´ë¥¼ contextë¡œ ë°”ë¡œ ì£¼ì… 
    chain = prompt | get_common_llm(temperature=0.5) | StrOutputParser()

    return chain.invoke({
        "context": json.dumps(analysis_data, ensure_ascii=False),
        "question": question,
        "age": age,
        "gender": gender
    })


if __name__ == "__main__":
    # print("ì›¹ ì‚¬ì´íŠ¸ ì´ìš© ë°©ë²•ì— ëŒ€í•´ ì§ˆë¬¸í•´ ë³´ì„¸ìš”! (ì¢…ë£Œ: 'exit' ë˜ëŠ” 'quit' ë˜ëŠ” 'ì¢…ë£Œ')")
    # while True:
    #     question = input("ì§ˆë¬¸: ").strip()
    #     if not question:
    #         print("ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”. (ì¢…ë£Œ: 'exit' ë˜ëŠ” 'quit' ë˜ëŠ” 'ì¢…ë£Œ')")
    #         continue
    #     if question.lower() in {"exit", "quit"} or question == "ì¢…ë£Œ":
    #         print("ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    #         break
    #     _print_search_results(question)
    #     answer = get_chatbot_answer(question)
    #     print('ë‹µë³€:', answer)
    question = "ë‚˜ë¬´ê°€ ë„ˆë¬´ ì§§ì€ë° ë¬´ìŠ¨ ì˜ë¯¸ê°€ ìˆëŠ” ê±´ê°€ìš”?"
    response = ask_psych_analysis(question, 8, "ì—¬")
    if not response: 
        print('ë‹µë³€ ì‹¤íŒ¨')
    else:
        print(response)

# ì§ˆë¬¸: ê·¸ë¦¼ ì¸ì‹ì„ ë” ì˜ ì‹œí‚¤ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?


    
