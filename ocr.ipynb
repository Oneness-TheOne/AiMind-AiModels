{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2e7454f",
   "metadata": {},
   "source": [
    "# 환경설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3d1c89",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3545016517.py, line 4)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m=`/-* 1. 모든 변수 참조 해제 시도\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "# 1. 모든 변수 참조 해제 시도\n",
    "if 'model' in locals():\n",
    "    del model\n",
    "if 'inputs' in locals():\n",
    "    del inputs\n",
    "\n",
    "# 2. 파이썬 가비지 컬렉션 실행\n",
    "gc.collect()\n",
    "\n",
    "# 3. PyTorch 캐시 비우기\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "print(\"GPU 메모리가 정리되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78a6b63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ddddwoo\\project\\Oneness\\AiMind-AiModels\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 설치(import)\n",
    "import os\n",
    "import torch\n",
    "import gc\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, LlavaOnevisionForConditionalGeneration, BitsAndBytesConfig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13832c03",
   "metadata": {},
   "source": [
    "# VARCO VISION 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4e652d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OCR 결과 ===\n",
      "2021년0.083, 0.071, 0.213, 0.123\n",
      "8월0.229, 0.071, 0.303, 0.123\n",
      "1일0.323, 0.071, 0.389, 0.123\n",
      "일요일0.397, 0.071, 0.49, 0.127\n",
      "날씨0.51, 0.071, 0.57, 0.117\n",
      "일어난0.083, 0.157, 0.15, 0.185\n",
      "시간:0.153, 0.157, 0.21, 0.185\n",
      "8시0.233, 0.151, 0.323,\n"
     ]
    }
   ],
   "source": [
    "# [필수] 메모리 파편화 방지 및 관리 설정\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "def clean_memory():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "clean_memory()\n",
    "\n",
    "model_id = \"NCSOFT/VARCO-VISION-2.0-1.7B-OCR\"\n",
    "\n",
    "# 1. 4비트 양자화 + CPU 오프로딩 준비\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    ")\n",
    "\n",
    "# 2. 모델 로드 (low_cpu_mem_usage 추가)\n",
    "model = LlavaOnevisionForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"sdpa\",\n",
    "    low_cpu_mem_usage=True # CPU 메모리 사용 최적화\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "# 3. 이미지 크기 극단적 축소 (성공 여부 확인용)\n",
    "image_path = \"test.png\"\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "# 512나 768로 대폭 낮춥니다. (6GB에서는 1024도 벅찰 수 있습니다)\n",
    "target_size = 512 \n",
    "w, h = image.size\n",
    "if max(w, h) > target_size:\n",
    "    scale = target_size / max(w, h)\n",
    "    image = image.resize((int(w * scale), int(h * scale)), resample=Image.LANCZOS)\n",
    "\n",
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"image\": image},\n",
    "            {\"type\": \"text\", \"text\": \"<ocr>\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "# 4. 입력 데이터 처리\n",
    "inputs = processor.apply_chat_template(\n",
    "    conversation,\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=True,\n",
    "    return_dict=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "\n",
    "# 5. 추론 (더 쥐어짜기)\n",
    "clean_memory()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    generate_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=256, # 토큰 수를 확 줄여서 메모리 압박 해소\n",
    "        do_sample=False,\n",
    "        use_cache=True\n",
    "    )\n",
    "\n",
    "# 6. 결과 출력\n",
    "output = processor.decode(generate_ids[0][len(inputs.input_ids[0]):], skip_special_tokens=True)\n",
    "print(\"\\n=== OCR 결과 ===\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "864b5b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 정제된 OCR 결과 ===\n",
      "2021년 8월 1일 일요일 날씨 일어난 시간: 8시 참드는 시간: 9시 제목: 한국의 여름 그림일기 공모전 한국 무나원 에서 한 국 여름을 주 재료 그림 일기 공모전을 한다. 자세한 내용 은 홍폐이지\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# ... (이전 추론 코드는 동일, max_new_tokens만 1024로 다시 늘려주세요)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    generate_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=1024, # 좌표값이 길어서 넉넉하게 줘야 끝까지 나옵니다.\n",
    "        do_sample=False,\n",
    "        use_cache=True\n",
    "    )\n",
    "\n",
    "# 결과 디코딩\n",
    "full_output = processor.decode(generate_ids[0][len(inputs.input_ids[0]):], skip_special_tokens=True)\n",
    "\n",
    "# 정규표현식을 사용해 숫자 좌표(0.123, 0.456 등)를 제거하는 함수\n",
    "def clean_ocr_text(text):\n",
    "    # 소수점 숫자가 포함된 좌표 패턴을 찾아 제거합니다.\n",
    "    cleaned = re.sub(r'\\d+\\.\\d+,\\s*\\d+\\.\\d+,\\s*\\d+\\.\\d+,\\s*\\d+\\.\\d+', '', text)\n",
    "    # 남은 숫자 조각들이나 불필요한 공백 정리\n",
    "    cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n",
    "    return cleaned\n",
    "\n",
    "print(\"\\n=== 정제된 OCR 결과 ===\")\n",
    "print(clean_ocr_text(full_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b817d97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
