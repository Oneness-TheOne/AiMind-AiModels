{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2e7454f",
   "metadata": {},
   "source": [
    "# 환경설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78a6b63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1단계: 라이브러리 임포트 및 환경설정 완료!\n"
     ]
    }
   ],
   "source": [
    "# [Cell 1] 환경설정 및 라이브러리 임포트\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, LlavaOnevisionForConditionalGeneration, BitsAndBytesConfig\n",
    "\n",
    "# 메모리 파편화 방지 설정\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "def clean_memory():\n",
    "    \"\"\"VRAM 메모리 캐시를 비우는 함수\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "clean_memory()\n",
    "print(\"1단계: 라이브러리 임포트 및 환경설정 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff949db",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95d9c6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2단계: 전처리 함수 준비 완료!\n"
     ]
    }
   ],
   "source": [
    "# [Cell 2] 전처리 함수 정의 (OpenCV)\n",
    "\n",
    "def order_points(pts):\n",
    "    \"\"\"좌표 정렬 (좌상, 우상, 우하, 좌하 순서)\"\"\"\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    return rect\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "    \"\"\"투시 변환 (찌그러진 사각형 펴기)\"\"\"\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "    dst = np.array([[0, 0], [maxWidth - 1, 0], [maxWidth - 1, maxHeight - 1], [0, maxHeight - 1]], dtype=\"float32\")\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    return cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "\n",
    "def dewarp_book_page(img, curve_intensity=20):\n",
    "    \"\"\"책 곡면 보정\"\"\"\n",
    "    rows, cols = img.shape[:2]\n",
    "    if len(img.shape) == 2:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    dst = np.zeros((rows, cols, 3), dtype=\"uint8\")\n",
    "    alpha = np.radians(curve_intensity)\n",
    "    r = cols / alpha \n",
    "    cy, cx = rows / 2, cols / 2\n",
    "    y_indices, x_indices = np.indices((rows, cols))\n",
    "    x_map = r * np.sin((x_indices - cx) / r) + cx\n",
    "    y_map = (y_indices - cy) * (r / np.sqrt(np.square(r) - np.square(x_indices - cx))) + cy\n",
    "    dst = cv2.remap(img, x_map.astype(np.float32), y_map.astype(np.float32), \n",
    "                    interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)\n",
    "    return dst\n",
    "\n",
    "def expand_contour(cnt, scale=1.03):\n",
    "    \"\"\"윤곽선 영역 살짝 확장\"\"\"\n",
    "    M = cv2.moments(cnt)\n",
    "    if M['m00'] == 0:\n",
    "        return cnt\n",
    "    cx = int(M['m10'] / M['m00'])\n",
    "    cy = int(M['m01'] / M['m00'])\n",
    "    cnt_norm = cnt - [cx, cy]\n",
    "    cnt_scaled = cnt_norm * scale\n",
    "    cnt_new = cnt_scaled + [cx, cy]\n",
    "    return cnt_new.astype(np.int32)\n",
    "\n",
    "def preprocess_document(image_path):\n",
    "    \"\"\"\n",
    "    [핵심 함수] 이미지 경로를 받아 전처리(Crop -> Dewarp) 후 PIL Image 객체 반환\n",
    "    \"\"\"\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"파일 없음: {image_path}\")\n",
    "        return None\n",
    "\n",
    "    cv_image = cv2.imread(image_path)\n",
    "    if cv_image is None: return None\n",
    "    \n",
    "    orig = cv_image.copy()\n",
    "    ratio = cv_image.shape[0] / 500.0\n",
    "    h = 500\n",
    "    w = int(cv_image.shape[1] / ratio)\n",
    "    image_resized = cv2.resize(cv_image, (w, h))\n",
    "\n",
    "    # 윤곽선 검출\n",
    "    gray = cv2.cvtColor(image_resized, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edged = cv2.Canny(gray, 50, 150)\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    edged = cv2.dilate(edged, kernel, iterations=1)\n",
    "    \n",
    "    cnts = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    cnts = sorted(cnts, key=cv2.contourArea, reverse=True)[:5]\n",
    "\n",
    "    screenCnt = None\n",
    "    for c in cnts:\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "        if len(approx) == 4:\n",
    "            screenCnt = approx\n",
    "            break\n",
    "\n",
    "    # 윤곽선 못 찾으면 원본 사용\n",
    "    if screenCnt is None:\n",
    "        print(\">> 문서 윤곽선을 찾지 못해 원본 이미지를 사용합니다.\")\n",
    "        return Image.fromarray(cv2.cvtColor(orig, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # 변환 적용\n",
    "    screenCnt = expand_contour(screenCnt, scale=1.03)\n",
    "    warped = four_point_transform(orig, screenCnt.reshape(4, 2) * ratio)\n",
    "    final_result = dewarp_book_page(warped, curve_intensity=15)\n",
    "    \n",
    "    print(\">> 전처리(문서 영역 추출 및 보정) 성공!\")\n",
    "    return Image.fromarray(cv2.cvtColor(final_result, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "print(\"2단계: 전처리 함수 준비 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13832c03",
   "metadata": {},
   "source": [
    "# VARCO VISION 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4e652d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[img1.jpg] 처리 시작...\n",
      ">> 전처리(문서 영역 추출 및 보정) 성공!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== OCR 결과 ====================\n",
      "일 수 요 억 오늘은 크레어 셋 을했다. 오늘은 은데 크레어 셋을했다. 오늘은 레모리 이션은 피구다. 그 리고남자, 여자팀으로 했다.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# [Cell 3] 모델 로드 및 OCR 실행\n",
    "\n",
    "# 1. 모델 설정 (이미 로드되어 있으면 건너뜀)\n",
    "if 'model' not in locals():\n",
    "    print(\"모델 로딩 중...\")\n",
    "    model_id = \"NCSOFT/VARCO-VISION-2.0-1.7B-OCR\"\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "    )\n",
    "    model = LlavaOnevisionForConditionalGeneration.from_pretrained(\n",
    "        model_id, quantization_config=bnb_config, device_map=\"auto\", attn_implementation=\"sdpa\", low_cpu_mem_usage=True\n",
    "    )\n",
    "    processor = AutoProcessor.from_pretrained(model_id)\n",
    "    print(\"모델 로드 완료!\")\n",
    "\n",
    "def clean_ocr_text(text):\n",
    "    cleaned = re.sub(r'\\d+\\.\\d+,\\s*\\d+\\.\\d+,\\s*\\d+\\.\\d+,\\s*\\d+\\.\\d+', '', text)\n",
    "    return re.sub(r'\\s+', ' ', cleaned).strip()\n",
    "\n",
    "# ==========================================\n",
    "# [입력] 처리할 파일명 입력\n",
    "# ==========================================\n",
    "target_file_path = \"img1.jpg\"  # <--- 여기를 수정하세요\n",
    "# ==========================================\n",
    "\n",
    "if os.path.exists(target_file_path):\n",
    "    try:\n",
    "        # [Step 1] 전처리 함수 호출\n",
    "        print(f\"[{target_file_path}] 처리 시작...\")\n",
    "        image = preprocess_document(target_file_path) # 위에서 만든 함수 사용\n",
    "        \n",
    "        # [Step 2] 모델 입력 준비\n",
    "        target_size = 512\n",
    "        w, h = image.size\n",
    "        if max(w, h) > target_size:\n",
    "            scale = target_size / max(w, h)\n",
    "            image = image.resize((int(w * scale), int(h * scale)), resample=Image.LANCZOS)\n",
    "\n",
    "        conversation = [\n",
    "            {\"role\": \"user\", \"content\": [{\"type\": \"image\", \"image\": image}, {\"type\": \"text\", \"text\": \"<ocr>\"}]}\n",
    "        ]\n",
    "        inputs = processor.apply_chat_template(\n",
    "            conversation, add_generation_prompt=True, tokenize=True, return_dict=True, return_tensors=\"pt\"\n",
    "        ).to(model.device)\n",
    "\n",
    "        # [Step 3] 추론\n",
    "        with torch.inference_mode():\n",
    "            generate_ids = model.generate(**inputs, max_new_tokens=1024, do_sample=False, use_cache=True)\n",
    "\n",
    "        full_output = processor.decode(generate_ids[0][len(inputs.input_ids[0]):], skip_special_tokens=True)\n",
    "        \n",
    "        print(f\"\\n{'='*20} OCR 결과 {'='*20}\")\n",
    "        print(clean_ocr_text(full_output))\n",
    "        print(f\"{'='*50}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"에러 발생: {e}\")\n",
    "    finally:\n",
    "        del inputs, generate_ids, image\n",
    "        clean_memory()\n",
    "else:\n",
    "    print(\"파일을 찾을 수 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6729f22e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
